Master_Script.R script is in folder 1. 
This program contains the entire code that extracted 8 of the 10 required columns for the project. It is masked inside a function that, when ran, asks for the user to input a desired year and extracts all the related columns in each article, journal, and volume for all years starting from the given year up to the most current article on the DNA research website. It contains if-else condition for determining the DOI of the article since the issues throughout the years have exact month of issue. For instance, all issue 1 of the journals throughout the years will have the same month in each year. The method used for extracting the data for each of the required columns was bringing the html code of each article web page and extract each column (i.e Title, Author, …etc) by its specific html tag(i.e div tag, “a” tag…). The tags were retrieved through piping by using dplyr package. All the code for scraping the tag is then brought into for loops in order to extract info for different years. We also used system delay functionality in our program since the website thought we were a bot after several requests and asked for user verification. The system delay slowed down the program but allowed us to extract and scrape the journal pages more effectively and smoothly. Another functionality of our code is for columns that have values of length more than 1. For instance, the Author column would have multiple values because each article has multiple authors. We had to put the author names into a comma-separated format and put them together in an empty list and the program stores all of them. The final step was to store all the scraped and retrieved data into a txt file. Each row in the output text file would have the 8 columns of each article separated by tab. 


RHtmlScript.R script is in folder 1.
This program only doesnt do any web scraping. It only extracts the web page for each article, and creates an html for each of the article web pages.


ReadTextFile.R script is in folder 3. 
We are storing out text file in table format with tab separators and calling it ArticleData.txt. This program reads that text file with a read.table command.